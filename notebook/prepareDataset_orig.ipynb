{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf7d6c6d",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a3de49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df26a282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in\n",
    "datasetInputFile = '../training/dataset/spam-dataset.csv'\n",
    "# out\n",
    "trainingDumpFile = '../training/prepared_dataset/spam_training_data.pickle'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1ff672",
   "metadata": {},
   "source": [
    "## Reading and transforming the input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630bbea3",
   "metadata": {},
   "source": [
    "#### Reading the input file and preparing legend info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145a897d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(datasetInputFile)\n",
    "labels = df['label'].tolist()\n",
    "texts = df['text'].tolist()\n",
    "#\n",
    "labelLegend = {'ham': 0, 'spam': 1}\n",
    "labelLegendInverted = {'%i' % v: k for k,v in labelLegend.items()}\n",
    "labelsAsInt = [labelLegend[x] for x in labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13813813",
   "metadata": {},
   "source": [
    "**Look at:** the contents of `texts`,\n",
    "`labelLegend`,\n",
    "`labelLegendInverted`,\n",
    "`labels`,\n",
    "`labelsAsInt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035316d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncomment any one of the following and press Shift+Enter to print the variable\n",
    "# texts\n",
    "# labelLegend\n",
    "# labelLegendInverted\n",
    "# labels\n",
    "# labelsAsInt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e525f5",
   "metadata": {},
   "source": [
    "#### Tokenization of texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63703572",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NUM_WORDS = 280\n",
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b0bd32",
   "metadata": {},
   "source": [
    "**Look at:** `tokenizer.word_index`, `inverseWordIndex`, `sequences` and how they play together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14c6151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is only needed for demonstration purposes, will not be dumped with the rest:\n",
    "inverseWordIndex = {v: k for k, v in tokenizer.word_index.items()}\n",
    "\n",
    "## Uncomment any one of the following and press Shift+Enter to print the variable\n",
    "# tokenizer.word_index\n",
    "# inverseWordIndex\n",
    "# sequences\n",
    "# [[inverseWordIndex[i] for i in seq] for seq in sequences]\n",
    "# texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960eb0e1",
   "metadata": {},
   "source": [
    "#### Padding of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b129bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LENGTH = 300\n",
    "X = pad_sequences(sequences, maxlen=MAX_SEQ_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6500c6b3",
   "metadata": {},
   "source": [
    "**Look at:** `sequences`, `X` and compare their shape and contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03801bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncomment any one of the following and press Shift+Enter to print the variable\n",
    "# [len(s) for s in sequences]\n",
    "# len(sequences)\n",
    "# X.shape\n",
    "# type(X)\n",
    "# X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1de341",
   "metadata": {},
   "source": [
    "#### Switch to categorical form for labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4113cc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsAsIntArray = np.asarray(labelsAsInt)\n",
    "y = to_categorical(labelsAsIntArray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cb6486",
   "metadata": {},
   "source": [
    "**Look at:** `labelsAsIntArray`, `y` and how they relate to `labels` and `labelLegend`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d1b67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncomment any one of the following and press Shift+Enter to print the variable\n",
    "# labelsAsIntArray\n",
    "# labelsAsIntArray.shape\n",
    "# y.shape\n",
    "# y\n",
    "# labels\n",
    "# labelLegend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cd91e8",
   "metadata": {},
   "source": [
    "## Splitting the labeled dataset and saving everything to file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a4145e",
   "metadata": {},
   "source": [
    "#### Splitting dataset (train/test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd0fbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1e1d63",
   "metadata": {},
   "source": [
    "**Look at:** the shape of the four resulting numpy 2D arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a001f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncomment any one of the following and press Shift+Enter to print the variable\n",
    "# X_train.shape\n",
    "# X_test.shape\n",
    "# y_train.shape\n",
    "# y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9376418e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData = {\n",
    "    'X_train': X_train, \n",
    "    'X_test': X_test,\n",
    "    'y_train': y_train,\n",
    "    'y_test': y_test,\n",
    "    'max_words': MAX_NUM_WORDS,\n",
    "    'max_seq_length': MAX_SEQ_LENGTH,\n",
    "    'label_legend': labelLegend,\n",
    "    'label_legend_inverted': labelLegendInverted, \n",
    "    'tokenizer': tokenizer,\n",
    "}\n",
    "with open(trainingDumpFile, 'wb') as f:\n",
    "    pickle.dump(trainingData, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
